{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- Path of the Training dataset 1 -----------------#\n",
    "TRANING_DATASET_1 = \"C:/Users/venky/OneDrive/Desktop/NN/Assignment 2/new/Dataset 1/\"\n",
    "\n",
    "#----------- Path of the Noisy dataset 1 -------------------#\n",
    "NOISY_DATASET_1 = \"C:/Users/venky/OneDrive/Desktop/NN/Assignment 2/new/Noisy Dataset 1/\"\n",
    "\n",
    "#---------- Path of the Training dataset 2 -----------------#\n",
    "TRANING_DATASET_2 = \"C:/Users/venky/OneDrive/Desktop/NN/Assignment 2/new/Dataset 2/\"\n",
    "\n",
    "#----------- Path of the Noisy dataset 2 -------------------#\n",
    "NOISY_DATASET_2 = \"C:/Users/venky/OneDrive/Desktop/NN/Assignment 2/new/Noisy Dataset 2/\"\n",
    "\n",
    "#---------- Required Standard Deviations -----------------#\n",
    "STANDARD_DEVIATIONS = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "\n",
    "TITLE_1_NOISELESS = \"Graph of Fh and Ffa vs. Noiseless Alphanumeric Imagery (16x16 pixels) for Autoassociative DNN of Dataset 1\"\n",
    "TITLE_1_NOISE = \"Graph of Fh and Ffa vs. Noise Standard Deviation for noise-corrupted Alphanumeric Imagery (16x16 pixels) for Autoassociative DNN of Dataset 1\"\n",
    "\n",
    "TITLE_2_NOISELESS = \"Graph of Fh and Ffa vs. Noiseless Alphanumeric Imagery (16x16 pixels) for Autoassociative DNN of Dataset 2\"\n",
    "TITLE_2_NOISE = \"Graph of Fh and Ffa vs. Noise Standard Deviation for noise-corrupted Alphanumeric Imagery (16x16 pixels) for Autoassociative DNN of Dataset 2\"\n",
    "\n",
    "TITLE_3_NOISELESS = \"Graph of Fh and Ffa vs. Noiseless Alphanumeric Imagery (16x16 pixels) for Autoassociative DNN of Test Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an image to numpy array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imagetensor(imagedir):\n",
    "  '''\n",
    "    imagedir: The directory/path of the images to be converted to NumPy Array\n",
    "\n",
    "  '''\n",
    "  temp=[]\n",
    "  for image  in os.listdir(imagedir):\n",
    "    im= Image.open(imagedir+image)\n",
    "    im=im.convert('L')\n",
    "    temp.append(np.array(im))\n",
    "  \n",
    "  images=np.array(temp)\n",
    "  images=np.where(images<np.mean(images),0,1).astype('float64')\n",
    "  return images\n",
    "\n",
    "# Function to convert NumPy Array to 0s and 1s based on the thresold value\n",
    "def convert_array_to_0_and_1(array):\n",
    "  return np.where(array<np.mean(array),0,1).astype('float64')\n",
    "\n",
    "# Function to display the results of the predicted images\n",
    "def display(oi,pi,single_line=False):\n",
    "  '''\n",
    "    oi: Original Image data\n",
    "    pi: Predicted Image data\n",
    "  \n",
    "  '''\n",
    "  for i in range(oi.shape[0]):\n",
    "    fig, axis= plt.subplots(1,2) if single_line else plt.subplots(2,sharex=True)\n",
    "    plt.subplots_adjust(top=1)\n",
    "    axis[0].set_title('Original Image')\n",
    "    axis[1].set_title('Predicted Image')\n",
    "    axis[0].imshow(oi[i].reshape(16,16),cmap=\"gray\",)\n",
    "    axis[1].imshow(pi[i].reshape(16,16),cmap=\"gray\")\n",
    "\n",
    "\n",
    "def plot_data(all_metrics, title, noiseless=False):\n",
    "    fig,ax = plt.subplots()\n",
    "\n",
    "    ax.set_ylabel(\"Fh and Ffa\")\n",
    "    if not noiseless:\n",
    "      ax.set_title(title)\n",
    "      ax.set_xlabel(\"Gaussian Noise Level (stdev, at 10 pct xsecn)\")\n",
    "      ax.set_xlim(0.0009, 0.12)\n",
    "      ax.set_ylim(0,1.05)\n",
    "      ax.set_xscale(\"log\")\n",
    "      ax.set_xticks(STANDARD_DEVIATIONS)\n",
    "      ax.set_xticklabels(STANDARD_DEVIATIONS)\n",
    "\n",
    "      for i in range(10):\n",
    "        for j in STANDARD_DEVIATIONS:\n",
    "            ax.plot(j, all_metrics[j][i][0], 'o', color='black')\n",
    "            ax.plot(j, all_metrics[j][i][1], 'o', color='black', markerfacecolor='none')\n",
    "    else:\n",
    "      ax.set_title(title)\n",
    "      ax.set_xticks([0])\n",
    "      ax.set_xticklabels([\"Noiseless Data\"])\n",
    "      for i in range(10):\n",
    "            ax.plot(0, all_metrics[i][0], 'o', color='black')\n",
    "            ax.plot(0, all_metrics[i][1], 'o', color='black', markerfacecolor='none')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- Importing the training dataset 1 -----------------#\n",
    "X1_train = imagetensor(TRANING_DATASET_1)\n",
    "\n",
    "#---------- Importing the training dataset 2 -----------------#\n",
    "X2_train = imagetensor(TRANING_DATASET_2)\n",
    "\n",
    "#---------- Importing the testing dataset 1 -----------------#\n",
    "X1_test = imagetensor(TRANING_DATASET_1)\n",
    "\n",
    "#---------- Importing the testing dataset 2 -----------------#\n",
    "X2_test = imagetensor(TRANING_DATASET_2)\n",
    "\n",
    "\n",
    "\n",
    "#---------- Flatenning the array to feed it as input nodes to the model -----------------#\n",
    "X1_train = X1_train.reshape(X1_train.shape[0],1,256)\n",
    "X2_train = X2_train.reshape(X2_train.shape[0],1,256)\n",
    "\n",
    "X1_test = X1_test.reshape(X1_test.shape[0],1,256)\n",
    "X2_test = X2_test.reshape(X2_test.shape[0],1,256)\n",
    "print(X1_train.shape,X1_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model for Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- Creating the model for dataset 1 -----------------#\n",
    "#---------- Using Relu as Activation Function -----------------#\n",
    "#---------- Configuring the model with 256 Input and Output nodes -----------------#\n",
    "ds1_model = keras.Sequential([\n",
    "    keras.layers.Dense(256,activation=tf.nn.relu,input_shape=(1,256)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256,activation=tf.nn.relu)\n",
    "])\n",
    "\n",
    "#------- Using Mean Squared Error as the loss function --------------#\n",
    "ds1_model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "print('Model Summary')\n",
    "ds1_model.summary()\n",
    "\n",
    "#------- Training the model --------------#\n",
    "ds1_model.fit(X1_train,X1_test,epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Model 1 with Test data for Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Predicting the dataset with the trained model --------------#\n",
    "X1_predict = ds1_model.predict(X1_test)\n",
    "\n",
    "X1_predict = convert_array_to_0_and_1(X1_predict)\n",
    "X1_test = convert_array_to_0_and_1(X1_test)\n",
    "print(X1_predict.shape,X1_test.shape)\n",
    "\n",
    "#------- Displaying the results of the predictions --------------#\n",
    "display(X1_test,X1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model for Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1, 256)            65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 64)             16448     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 64)             4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 256)            16640     \n",
      "=================================================================\n",
      "Total params: 103,040\n",
      "Trainable params: 103,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5070\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4674\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4450\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4173\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4016\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3795\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3646\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3534\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3382\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3169\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3082\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2933\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2808\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2718\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2558\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2579\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2401\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2399\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2321\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2226\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2254\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2198\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2166\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2093\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2058\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2067\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2028\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2013\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1984\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1995\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1974\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1934\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1996\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1985\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1928\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1907\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1895\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1864\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1889\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1852\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1820\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1821\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1817\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1816\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1822\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1772\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1783\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1821\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1782\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1752\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1733\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1798\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1712\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1744\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1793\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1705\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1699\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1660\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1703\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1694\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1716\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1650\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1705\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1693\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1648\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1672\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1676\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1654\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1568\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1583\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1536\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1557\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1509\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1517\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1524\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1547\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1558\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1502\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1541\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1530\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1485\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1499\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1458\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1504\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1515\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1470\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1430\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1454\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1465\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1462\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1447\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1456\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1498\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1454\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1450\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1482\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1430\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1435\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1501\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1417\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1439\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1416\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1422\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1384\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1452\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1386\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1419\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1392\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1373\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1381\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1336\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1319\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1346\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1302\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1306\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1294\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1301\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1297\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1375\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1254\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1306\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1274\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1225\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1239\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1267\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1221\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1251\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1208\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1247\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1244\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1242\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1210\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1177\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1191\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1260\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1228\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1177\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1202\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1227\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1167\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1181\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1248\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1160\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1201\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1251\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2690f041250>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------- Creating the model for dataset 2 -----------------#\n",
    "#---------- Using Relu as Activation Function -----------------#\n",
    "#---------- Configuring the model with 256 Input and Output nodes -----------------#\n",
    "ds2_model = keras.Sequential([\n",
    "    keras.layers.Dense(256,activation=tf.nn.relu,input_shape=(1,256)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256,activation=tf.nn.relu)\n",
    "])\n",
    "\n",
    "#------- Using Mean Squared Error as the loss function --------------#\n",
    "ds2_model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "print('Model Summary')\n",
    "ds2_model.summary()\n",
    "\n",
    "#------- Training the model --------------#\n",
    "ds2_model.fit(X2_train, X2_test,epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Model 2 with Test data for Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Predicting the dataset with the trained model --------------#\n",
    "X2_predict = ds2_model.predict(X2_test)\n",
    "\n",
    "X2_predict = convert_array_to_0_and_1(X2_predict)\n",
    "X2_test = convert_array_to_0_and_1(X2_test)\n",
    "print(X2_predict.shape,X2_test.shape)\n",
    "\n",
    "#------- Displaying the results of the predictions --------------#\n",
    "display(X2_test,X2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Noise to Images for Dataset 1 and Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Function to generate Gaussian Noise at 25 random pixels in the Image --------------#\n",
    "def noisy(images, noisy_path):\n",
    "    '''\n",
    "        images: list of images to add noise to\n",
    "    '''\n",
    "    for std in STANDARD_DEVIATIONS:\n",
    "        for image_name, image in enumerate(images):\n",
    "            row,col= image.shape\n",
    "            noise_pixels=np.ones([16,16],dtype='float64')\n",
    "            mean = 0\n",
    "\n",
    "            #------- Generating gaussian noise with required standard deviation --------------#        \n",
    "            gauss = np.random.normal(mean,std**0.5,(row,col))\n",
    "            for _ in range(25):\n",
    "                x=np.random.choice(16)\n",
    "                y=np.random.choice(16)\n",
    "                noise_pixels[x][y]=gauss[x][y]\n",
    "            \n",
    "            #------- Adding the generated noise to the image --------------#\n",
    "            noisy = image + noise_pixels\n",
    "            noisy = convert_array_to_0_and_1(noisy)\n",
    "\n",
    "            #------- Saving the Noisy Image to Noisy Folder --------------#\n",
    "            plt.imsave(f\"{noisy_path}{std}/{image_name}.jpg\",noisy,cmap='gray')\n",
    "    return noisy\n",
    "\n",
    "\n",
    "#------- Adding noise to dataset 1 --------------#\n",
    "noisy(imagetensor(TRANING_DATASET_1), NOISY_DATASET_1)\n",
    "\n",
    "#------- Adding noise to dataset 2 --------------#\n",
    "noisy(imagetensor(TRANING_DATASET_2), NOISY_DATASET_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Noise Added Images over Original Images for Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Predicting the noisy images of dataset 1 with the model 1 --------------#\n",
    "ds1_noisy_model_prediction_data = {}\n",
    "print(\"Predictions for Noisy data with Standard Deviation\")\n",
    "for std in STANDARD_DEVIATIONS:\n",
    "    ds1_noisy_model = imagetensor(f\"{NOISY_DATASET_1}{std}/\")\n",
    "    ds1_noisy_model = ds1_noisy_model.reshape(ds1_noisy_model.shape[0],1,256)\n",
    "    ds1_noisy_model = convert_array_to_0_and_1(ds1_noisy_model)\n",
    "\n",
    "    ds1_noisy_predict = ds1_model.predict(ds1_noisy_model)\n",
    "    ds1_noisy_predict = convert_array_to_0_and_1(ds1_noisy_predict)\n",
    "    \n",
    "    ds1_noisy_model_prediction_data[std] = ds1_noisy_predict\n",
    "    display(ds1_noisy_model, ds1_noisy_predict,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Noise Added Images over Original Images for Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Predicting the noisy images of dataset 2 with the model 2 --------------#\n",
    "ds2_noisy_model_prediction_data = {}\n",
    "print(\"Predictions for Noisy data with Standard Deviation\")\n",
    "for std in STANDARD_DEVIATIONS:\n",
    "    ds2_noisy_model = imagetensor(f\"{NOISY_DATASET_2}{std}/\")\n",
    "    ds2_noisy_model = ds2_noisy_model.reshape(ds2_noisy_model.shape[0],1,256)\n",
    "    ds2_noisy_model = convert_array_to_0_and_1(ds2_noisy_model)\n",
    "\n",
    "    ds2_noisy_predict = ds2_model.predict(ds2_noisy_model)\n",
    "    ds2_noisy_predict = convert_array_to_0_and_1(ds2_noisy_predict)\n",
    "    \n",
    "    ds2_noisy_model_prediction_data[std] = ds2_noisy_predict\n",
    "    display(ds2_noisy_model, ds2_noisy_predict,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulation and Graph Generation of Fh and Ffa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Function for calculating FFA and FH values --------------#\n",
    "def calculate_fh_ffa(original_data, predicted_data):\n",
    "    '''\n",
    "        original_data: Original Image data\n",
    "        predicted_data: Predicted Image data\n",
    "        \n",
    "    '''\n",
    "\n",
    "    correctly_predicted_black_pixels_count = 0\n",
    "    wrongly_predicted_black_pixels_count = 0\n",
    "\n",
    "    whites_original = np.count_nonzero(original_data==1)\n",
    "    blacks_original = np.count_nonzero(original_data==0)\n",
    "\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            if original_data[i][j] == 0 and predicted_data[i][j] == 0:\n",
    "                correctly_predicted_black_pixels_count += 1\n",
    "            elif original_data[i][j] == 1 and predicted_data[i][j] == 0:\n",
    "                wrongly_predicted_black_pixels_count += 1\n",
    "                \n",
    "    fh = correctly_predicted_black_pixels_count/blacks_original\n",
    "    ffa = wrongly_predicted_black_pixels_count/whites_original\n",
    "    \n",
    "    return fh,ffa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Calculating the FFA and FH values for all the Predicted Images for both Trained and Noisy datasets of dataset 1--------------#\n",
    "ds1_all_metrics = {}\n",
    "ds1_metric_original = X1_train\n",
    "ds1_metric_predicted = X1_predict\n",
    "ds1_noisy_model_prediction_data[0] = ds1_metric_predicted\n",
    "\n",
    "ds1_metric_original = ds1_metric_original.reshape(ds1_metric_original.shape[0],16,16)\n",
    "\n",
    "for k,v in ds1_noisy_model_prediction_data.items():\n",
    "\n",
    "    ds1_metric_predicted = v.reshape(v.shape[0],16,16)\n",
    "    ds1_all_metrics[k] = {}\n",
    "    \n",
    "    for i in range(36):\n",
    "        ds1_all_metrics[k][i] = calculate_fh_ffa(ds1_metric_original[i],ds1_metric_predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Plotting all the results of Dataset 1 --------------#\n",
    "plot_data(ds1_all_metrics[0], TITLE_1_NOISELESS, noiseless=True)\n",
    "\n",
    "plot_data(ds1_all_metrics, TITLE_1_NOISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Calculating the FFA and FH values for all the Predicted Images for both Trained and Noisy datasets of dataset 2--------------#\n",
    "ds2_all_metrics = {}\n",
    "ds2_metric_original = X2_train\n",
    "ds2_metric_predicted = X2_predict\n",
    "ds2_noisy_model_prediction_data[0] = ds2_metric_predicted\n",
    "\n",
    "ds2_metric_original = ds2_metric_original.reshape(ds2_metric_original.shape[0],16,16)\n",
    "\n",
    "for k,v in ds2_noisy_model_prediction_data.items():\n",
    "\n",
    "    ds2_metric_predicted = v.reshape(v.shape[0],16,16)\n",
    "\n",
    "    ds2_all_metrics[k] = {}\n",
    "    \n",
    "    for i in range(36):\n",
    "        ds2_all_metrics[k][i] = calculate_fh_ffa(ds2_metric_original[i],ds2_metric_predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Plotting all the results of dataset 2 --------------#\n",
    "plot_data(ds2_all_metrics[0], TITLE_2_NOISELESS, noiseless=True)\n",
    "\n",
    "plot_data(ds2_all_metrics, TITLE_2_NOISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(metrics, title):\n",
    "    colors = ['#0000ff', '#cc33ff', '#006666', '#cccc00', '#33cc33', '#ff5050', '#cc9900', '#993300', '#009933', '#990000']\n",
    "    roc_fh_values = {}\n",
    "    roc_ffa_values = {}\n",
    "    for std in metrics.keys():\n",
    "        roc_fh_values[std] = []\n",
    "        roc_ffa_values[std] = []\n",
    "        for i in metrics[std].keys():\n",
    "            roc_fh_values[std].append(metrics[std][i][0])\n",
    "            roc_ffa_values[std].append(metrics[std][i][1])\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    for std, color in zip(metrics.keys(), colors):\n",
    "        fh = roc_fh_values[std]\n",
    "        ffa = roc_ffa_values[std]\n",
    "        fh.sort()\n",
    "        ffa.sort()\n",
    "\n",
    "        ax.plot(ffa,fh, color=color, label= f\"ROC curve of stddev {std}\")\n",
    "        ax.plot([0, 1], [0, 1], linestyle='--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.0])\n",
    "        ax.set_xlabel('Ffa')\n",
    "        ax.set_ylabel('Fh')\n",
    "        ax.set_title(title)\n",
    "        ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_plot(ds1_all_metrics, \"ROC curve for Dataset 1\")\n",
    "\n",
    "roc_curve_plot(ds2_all_metrics, \"ROC curve for Dataset 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model 1 with Model 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------- Predicting the dataset with the trained model --------------#\n",
    "X3_predict = ds1_model.predict(X2_test)\n",
    "\n",
    "X3_predict = convert_array_to_0_and_1(X3_predict)\n",
    "X2_test = convert_array_to_0_and_1(X2_test)\n",
    "print(X3_predict.shape,X2_test.shape)\n",
    "\n",
    "#------- Displaying the results of the predictions --------------#\n",
    "display(X2_test,X3_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_all_metrics = {}\n",
    "test_data_all_metrics[0] = {}\n",
    "test_data_metric_original = X2_train\n",
    "test_data_metric_predicted = X3_predict\n",
    "\n",
    "test_data_metric_original = test_data_metric_original.reshape(test_data_metric_original.shape[0],16,16)\n",
    "test_data_metric_predicted = test_data_metric_predicted.reshape(test_data_metric_predicted.shape[0],16,16)\n",
    "\n",
    "for i in range(36):\n",
    "    test_data_all_metrics[0][i] = calculate_fh_ffa(test_data_metric_original[i],test_data_metric_predicted[i])\n",
    "\n",
    "\n",
    "#------- Plotting all the results of Test Dataset --------------#\n",
    "plot_data(test_data_all_metrics[0], TITLE_3_NOISELESS, noiseless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "[[row[i] for row in matrix] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "days = [\"M\", \"T\", \"W\", \"TH\"]\n",
    "c = Counter(days)\n",
    "\n",
    "for x in range(1,5,2):\n",
    "    d = x % 3\n",
    "    c.update([days[d]]*x)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class a:\n",
    "    def __init__(self,n):\n",
    "        self.n = n\n",
    "    def t(self):\n",
    "        return f\"my nmae is {self.n}\"\n",
    "class c(a):\n",
    "    def t(self):\n",
    "        sp = super().t()\n",
    "        return f\"m {sp}\"\n",
    "c(n=\"fido\").t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1:1,2:2}\n",
    "i = d.items()\n",
    "\n",
    "d.pop(1)\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds1_all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds2_all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8e5483870c41da2baeb5f2e04aa37a619a63b47a86b23a84f951a3d3fa4a1e7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('py36': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
