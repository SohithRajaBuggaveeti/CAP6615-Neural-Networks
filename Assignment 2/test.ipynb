{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0         6     149     149     150     150     150     151     151     150   \n",
      "1         5     126     128     131     132     133     134     135     135   \n",
      "2        10      85      88      92      96     105     123     135     143   \n",
      "3         0     203     205     207     206     207     209     210     209   \n",
      "4         3     188     191     193     195     199     201     202     203   \n",
      "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "7167      1     135     119     108     102     105      99      61     103   \n",
      "7168     12     157     159     161     164     166     166     171     174   \n",
      "7169      2     190     191     190     191     190     190     192     192   \n",
      "7170      4     201     205     208     209     214     216     218     223   \n",
      "7171      2     173     174     173     174     173     173     175     175   \n",
      "\n",
      "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0        151  ...       138       148       127        89        82        96   \n",
      "1        136  ...        47       104       194       183       186       184   \n",
      "2        147  ...        68       166       242       227       230       227   \n",
      "3        210  ...       154       248       247       248       253       236   \n",
      "4        203  ...        26        40        64        48        29        46   \n",
      "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
      "7167     121  ...       108       112       116       114       118       180   \n",
      "7168     175  ...       213       213       213       214       213       211   \n",
      "7169     191  ...       216       215       213       214       214       213   \n",
      "7170     226  ...       112       169       255       255       237       113   \n",
      "7171     174  ...       201       200       197       198       198       197   \n",
      "\n",
      "      pixel781  pixel782  pixel783  pixel784  \n",
      "0          106       112       120       107  \n",
      "1          184       184       182       180  \n",
      "2          226       225       224       222  \n",
      "3          230       240       253       255  \n",
      "4           49        46        46        53  \n",
      "...        ...       ...       ...       ...  \n",
      "7167       184       176       167       163  \n",
      "7168       210       210       209       208  \n",
      "7169       210       211       209       208  \n",
      "7170        91        67        70        63  \n",
      "7171       195       195       193       192  \n",
      "\n",
      "[7172 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "train = pd.read_csv('C:/Users/venky/OneDrive/Desktop/NN/Assignment 2/data/sign_mnist_test/sign_mnist_test.csv')\n",
    "test = pd.read_csv('C:/Users/venky/OneDrive/Desktop/NN/Assignment 2/data/sign_mnist_train/sign_mnist_train.csv')\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7172, 785)\n"
     ]
    }
   ],
   "source": [
    "#Datasets as numpy arrays\n",
    "train_data = np.array(train, dtype = 'float32')\n",
    "test_data = np.array(test, dtype='float32')\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "#Define class labels for easy interpretation\n",
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]\n",
    "\n",
    "#Sanity check - plot a few images and labels\n",
    "# i = random.randint(1,train.shape[0])\n",
    "# fig1, ax1 = plt.subplots(figsize=(2,2))\n",
    "# plt.imshow(train_data[i,1:].reshape((28,28)), cmap='gray') \n",
    "# print(\"Label for the image is: \", class_names[int(train_data[i,0])])\n",
    "\n",
    "\n",
    "# # Data distribution visualization\n",
    "# fig = plt.figure(figsize=(18,18))\n",
    "# ax1 = fig.add_subplot(221)\n",
    "# train['label'].value_counts().plot(kind='bar', ax=ax1)\n",
    "# ax1.set_ylabel('Count')\n",
    "# ax1.set_title('Label')\n",
    "\n",
    "#Dataset seems to be fairly balanced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7172, 784)\n",
      "[[[[0.58431375]\n",
      "   [0.58431375]\n",
      "   [0.5882353 ]\n",
      "   ...\n",
      "   [0.5882353 ]\n",
      "   [0.5882353 ]\n",
      "   [0.58431375]]\n",
      "\n",
      "  [[0.5882353 ]\n",
      "   [0.5882353 ]\n",
      "   [0.5882353 ]\n",
      "   ...\n",
      "   [0.5921569 ]\n",
      "   [0.5882353 ]\n",
      "   [0.5921569 ]]\n",
      "\n",
      "  [[0.5882353 ]\n",
      "   [0.5921569 ]\n",
      "   [0.5921569 ]\n",
      "   ...\n",
      "   [0.5921569 ]\n",
      "   [0.5921569 ]\n",
      "   [0.59607846]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.27058825]\n",
      "   [0.27058825]\n",
      "   [0.3019608 ]\n",
      "   ...\n",
      "   [0.45490196]\n",
      "   [0.44313726]\n",
      "   [0.4627451 ]]\n",
      "\n",
      "  [[0.2901961 ]\n",
      "   [0.29411766]\n",
      "   [0.29803923]\n",
      "   ...\n",
      "   [0.43137255]\n",
      "   [0.45490196]\n",
      "   [0.44313726]]\n",
      "\n",
      "  [[0.29411766]\n",
      "   [0.2901961 ]\n",
      "   [0.2901961 ]\n",
      "   ...\n",
      "   [0.4392157 ]\n",
      "   [0.47058824]\n",
      "   [0.41960785]]]\n",
      "\n",
      "\n",
      " [[[0.49411765]\n",
      "   [0.5019608 ]\n",
      "   [0.5137255 ]\n",
      "   ...\n",
      "   [0.52156866]\n",
      "   [0.5254902 ]\n",
      "   [0.5176471 ]]\n",
      "\n",
      "  [[0.5058824 ]\n",
      "   [0.5176471 ]\n",
      "   [0.5254902 ]\n",
      "   ...\n",
      "   [0.53333336]\n",
      "   [0.53333336]\n",
      "   [0.5254902 ]]\n",
      "\n",
      "  [[0.52156866]\n",
      "   [0.5294118 ]\n",
      "   [0.5411765 ]\n",
      "   ...\n",
      "   [0.54901963]\n",
      "   [0.54509807]\n",
      "   [0.5411765 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6784314 ]\n",
      "   [0.68235296]\n",
      "   [0.69411767]\n",
      "   ...\n",
      "   [0.72156864]\n",
      "   [0.7137255 ]\n",
      "   [0.70980394]]\n",
      "\n",
      "  [[0.6745098 ]\n",
      "   [0.68235296]\n",
      "   [0.69411767]\n",
      "   ...\n",
      "   [0.72156864]\n",
      "   [0.7137255 ]\n",
      "   [0.70980394]]\n",
      "\n",
      "  [[0.6745098 ]\n",
      "   [0.68235296]\n",
      "   [0.69411767]\n",
      "   ...\n",
      "   [0.72156864]\n",
      "   [0.7137255 ]\n",
      "   [0.7058824 ]]]\n",
      "\n",
      "\n",
      " [[[0.33333334]\n",
      "   [0.34509805]\n",
      "   [0.36078432]\n",
      "   ...\n",
      "   [0.7137255 ]\n",
      "   [0.70980394]\n",
      "   [0.69803923]]\n",
      "\n",
      "  [[0.3372549 ]\n",
      "   [0.34509805]\n",
      "   [0.3647059 ]\n",
      "   ...\n",
      "   [0.7176471 ]\n",
      "   [0.70980394]\n",
      "   [0.7019608 ]]\n",
      "\n",
      "  [[0.3372549 ]\n",
      "   [0.34901962]\n",
      "   [0.3647059 ]\n",
      "   ...\n",
      "   [0.7254902 ]\n",
      "   [0.7176471 ]\n",
      "   [0.70980394]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.35686275]\n",
      "   [0.36862746]\n",
      "   [0.38039216]\n",
      "   ...\n",
      "   [0.8784314 ]\n",
      "   [0.87058824]\n",
      "   [0.8666667 ]]\n",
      "\n",
      "  [[0.3529412 ]\n",
      "   [0.36078432]\n",
      "   [0.3764706 ]\n",
      "   ...\n",
      "   [0.88235295]\n",
      "   [0.8784314 ]\n",
      "   [0.87058824]]\n",
      "\n",
      "  [[0.34901962]\n",
      "   [0.35686275]\n",
      "   [0.36862746]\n",
      "   ...\n",
      "   [0.88235295]\n",
      "   [0.8784314 ]\n",
      "   [0.87058824]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.74509805]\n",
      "   [0.7490196 ]\n",
      "   [0.74509805]\n",
      "   ...\n",
      "   [0.7254902 ]\n",
      "   [0.72156864]\n",
      "   [0.7176471 ]]\n",
      "\n",
      "  [[0.75686276]\n",
      "   [0.75686276]\n",
      "   [0.75686276]\n",
      "   ...\n",
      "   [0.7294118 ]\n",
      "   [0.7254902 ]\n",
      "   [0.72156864]]\n",
      "\n",
      "  [[0.7647059 ]\n",
      "   [0.7607843 ]\n",
      "   [0.7647059 ]\n",
      "   ...\n",
      "   [0.73333335]\n",
      "   [0.7294118 ]\n",
      "   [0.73333335]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8392157 ]\n",
      "   [0.84313726]\n",
      "   [0.8352941 ]\n",
      "   ...\n",
      "   [0.8156863 ]\n",
      "   [0.8156863 ]\n",
      "   [0.8156863 ]]\n",
      "\n",
      "  [[0.8392157 ]\n",
      "   [0.84313726]\n",
      "   [0.81960785]\n",
      "   ...\n",
      "   [0.81960785]\n",
      "   [0.8156863 ]\n",
      "   [0.8117647 ]]\n",
      "\n",
      "  [[0.84313726]\n",
      "   [0.84313726]\n",
      "   [0.8117647 ]\n",
      "   ...\n",
      "   [0.827451  ]\n",
      "   [0.81960785]\n",
      "   [0.8156863 ]]]\n",
      "\n",
      "\n",
      " [[[0.7882353 ]\n",
      "   [0.8039216 ]\n",
      "   [0.8156863 ]\n",
      "   ...\n",
      "   [0.9372549 ]\n",
      "   [0.9372549 ]\n",
      "   [0.9372549 ]]\n",
      "\n",
      "  [[0.80784315]\n",
      "   [0.81960785]\n",
      "   [0.83137256]\n",
      "   ...\n",
      "   [0.9490196 ]\n",
      "   [0.9490196 ]\n",
      "   [0.9490196 ]]\n",
      "\n",
      "  [[0.8235294 ]\n",
      "   [0.8392157 ]\n",
      "   [0.84705883]\n",
      "   ...\n",
      "   [0.9647059 ]\n",
      "   [0.9607843 ]\n",
      "   [0.95686275]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.        ]\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [0.78431374]\n",
      "   [0.5568628 ]]\n",
      "\n",
      "  [[1.        ]\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [0.3882353 ]\n",
      "   [0.3137255 ]\n",
      "   [0.3019608 ]]\n",
      "\n",
      "  [[1.        ]\n",
      "   [1.        ]\n",
      "   [1.        ]\n",
      "   ...\n",
      "   [0.2627451 ]\n",
      "   [0.27450982]\n",
      "   [0.24705882]]]\n",
      "\n",
      "\n",
      " [[[0.6784314 ]\n",
      "   [0.68235296]\n",
      "   [0.6784314 ]\n",
      "   ...\n",
      "   [0.65882355]\n",
      "   [0.654902  ]\n",
      "   [0.6509804 ]]\n",
      "\n",
      "  [[0.6901961 ]\n",
      "   [0.6901961 ]\n",
      "   [0.6901961 ]\n",
      "   ...\n",
      "   [0.65882355]\n",
      "   [0.65882355]\n",
      "   [0.654902  ]]\n",
      "\n",
      "  [[0.69803923]\n",
      "   [0.69411767]\n",
      "   [0.69803923]\n",
      "   ...\n",
      "   [0.6627451 ]\n",
      "   [0.65882355]\n",
      "   [0.6627451 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7764706 ]\n",
      "   [0.78039217]\n",
      "   [0.78039217]\n",
      "   ...\n",
      "   [0.7529412 ]\n",
      "   [0.7529412 ]\n",
      "   [0.7529412 ]]\n",
      "\n",
      "  [[0.7764706 ]\n",
      "   [0.78431374]\n",
      "   [0.75686276]\n",
      "   ...\n",
      "   [0.75686276]\n",
      "   [0.7529412 ]\n",
      "   [0.7490196 ]]\n",
      "\n",
      "  [[0.78039217]\n",
      "   [0.7882353 ]\n",
      "   [0.74509805]\n",
      "   ...\n",
      "   [0.7647059 ]\n",
      "   [0.75686276]\n",
      "   [0.7529412 ]]]]\n"
     ]
    }
   ],
   "source": [
    "#Normalize / scale X values\n",
    "X_train = train_data[:, 1:] /255.\n",
    "X_test = test_data[:, 1:] /255.\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "#Convert y to categorical if planning on using categorical cross entropy\n",
    "#No need to do this if using sparse categorical cross entropy\n",
    "y_train = train_data[:, 0]\n",
    "y_train_cat = to_categorical(y_train, num_classes=25)\n",
    "\n",
    "y_test = test_data[:,0]\n",
    "y_test_cat = to_categorical(y_test, num_classes=25)\n",
    "\n",
    "#Reshape for the neural network\n",
    "X_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n",
    "print(X_train)\n",
    "X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\n",
    "\n",
    "#########################################################\n",
    "\n",
    "#Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                3225      \n",
      "=================================================================\n",
      "Total params: 112,409\n",
      "Trainable params: 112,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 3.1579 - acc: 0.0612 - val_loss: 3.1981 - val_acc: 0.0423\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 6s 104ms/step - loss: 2.9031 - acc: 0.1479 - val_loss: 2.7149 - val_acc: 0.1870\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 6s 101ms/step - loss: 2.0889 - acc: 0.3544 - val_loss: 2.0372 - val_acc: 0.3697\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 6s 101ms/step - loss: 1.4951 - acc: 0.5204 - val_loss: 1.6685 - val_acc: 0.4708\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 6s 107ms/step - loss: 1.1135 - acc: 0.6315 - val_loss: 1.3961 - val_acc: 0.5644\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 6s 105ms/step - loss: 0.8664 - acc: 0.7066 - val_loss: 1.3430 - val_acc: 0.5774\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 5s 93ms/step - loss: 0.6850 - acc: 0.7726 - val_loss: 1.2977 - val_acc: 0.6162\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 5s 95ms/step - loss: 0.5456 - acc: 0.8208 - val_loss: 1.2474 - val_acc: 0.6481\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 5s 94ms/step - loss: 0.4205 - acc: 0.8617 - val_loss: 1.2812 - val_acc: 0.6496\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 5s 96ms/step - loss: 0.3771 - acc: 0.8742 - val_loss: 1.2401 - val_acc: 0.6631\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(25, activation = 'softmax'))\n",
    "\n",
    "\n",
    "#If your targets are one-hot encoded, use categorical_crossentropy. Examples of one-hot encodings:\n",
    "# If your targets are integers, use sparse_categorical_crossentropy. \n",
    "\n",
    "#model.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['acc'])\n",
    "model.compile(loss ='categorical_crossentropy', optimizer='adam', metrics =['acc'])\n",
    "model.summary()\n",
    "\n",
    "#history = model.fit(X_train, y_train, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test))\n",
    "history = model.fit(X_train, y_train_cat, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test_cat))\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455,)\n",
      "(27455, 28, 28, 1)\n",
      "Predicted Label:  V\n",
      "True Label:  R\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(prediction.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "i = random.randint(1,len(prediction))\n",
    "plt.imshow(X_test[i,:,:,0], cmap=\"gray\") \n",
    "print(\"Predicted Label: \", class_names[int(prediction[i])])\n",
    "print(\"True Label: \", class_names[int(y_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8f6df1b1f8bac7ec930d85adb543c7eae57bf29b2f3c50fe66974438c488632"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
